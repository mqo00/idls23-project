{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "Ki1UnQSgUhRN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aleLjSIhTe_0",
        "outputId": "c36c7084-68ba-4ef2-9c9d-b434f9eb30f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Path\n",
        "csv_path = '/content/drive/MyDrive/11785_project/data/2020S/contributions.csv'"
      ],
      "metadata": {
        "id": "hNrbDz4RT-yx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read files\n",
        "csv_data = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "DScj8sP2Ejp9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## \n",
        "question_csv = csv_data.loc[csv_data['Part of Post'] == 'started_off_question']\n",
        "ianswer_csv = csv_data.loc[csv_data['Part of Post'] == 'started_off_i_answer']\n",
        "question_csv = question_csv[[\"Submission HTML Removed\",\"Subject\",\"Folders\"]]\n",
        "ianswer_csv = ianswer_csv[[\"Submission HTML Removed\",\"Subject\"]]"
      ],
      "metadata": {
        "id": "qA2wo7OzmJLs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_csv_list = question_csv.values.tolist()\n",
        "ianswer_csv_list = ianswer_csv.values.tolist()"
      ],
      "metadata": {
        "id": "EQvPzyUkmdpL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ianswer_csv_list),len(question_csv_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yplBjiKYpRjB",
        "outputId": "f5ff2793-4810-459a-c95a-8a140e35009c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1588, 1638)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{label:“”\n",
        "question:\"\"\n",
        "answer:\"\"}"
      ],
      "metadata": {
        "id": "3rUMPU5fphUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pair = []\n",
        "\n",
        "# question_copy = question_csv_list.copy()\n",
        "# ianswer_copy = ianswer_csv_list.copy()\n",
        "for i in range(len(question_csv_list)):\n",
        "  for j in range(len(ianswer_csv_list)):\n",
        "    if question_csv_list[i][1] == ianswer_csv_list[j][1]:\n",
        "      correct_pair.append([question_csv_list[i][1],\n",
        "                           ianswer_csv_list[j][1],\n",
        "                           question_csv_list[i][0],\n",
        "                           ianswer_csv_list[j][0],\n",
        "                           question_csv_list[i][2]])\n",
        "      break"
      ],
      "metadata": {
        "id": "0wGpRlH3Cqot"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pair[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0siePnuCqrr",
        "outputId": "df6ce2f4-6f34-4dc0-d7cf-344e759c4049"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can we mark the class inactive?',\n",
              " 'Can we mark the class inactive?',\n",
              " 'TIA!',\n",
              " 'some students are still posting questions for the summer make-up hws.\\xa0\\n\\nClosing the piazza though.',\n",
              " 'logistics']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmnan_pair = []\n",
        "for i in range(len(correct_pair)):\n",
        "  if type(correct_pair[i][2]) != float and type(correct_pair[i][3]) != float:\n",
        "    rmnan_pair.append(correct_pair[i])"
      ],
      "metadata": {
        "id": "8owX30hbCqu6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(rmnan_pair)"
      ],
      "metadata": {
        "id": "dtrjk4-fFKn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a68f6c-da5c-4f9d-8284-461522437ef3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1572"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(rmnan_pair)):\n",
        "  for j in range(len(rmnan_pair[i])):\n",
        "    rmnan_pair[i][j] = ' '.join(rmnan_pair[i][j].split('\\n'))\n",
        "    rmnan_pair[i][j] = ' '.join(rmnan_pair[i][j].split('\\t'))\n",
        "    rmnan_pair[i][j] = ' '.join(rmnan_pair[i][j].split('\\xa0'))"
      ],
      "metadata": {
        "id": "PQn5t1jkGApl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmnan_pair[-2]"
      ],
      "metadata": {
        "id": "AfL9I_SOGx7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b2c5e4-a96a-4041-aedf-8163e8955811"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BatchNorm Question',\n",
              " 'BatchNorm Question',\n",
              " 'my equation for dnorm = np.multiply(delta, self.gamma)   But I am receiving this error:    This is the first equation I am calculating and I have not made any changes to delta. Should I be making a change to delta here to make this work or should this work automatically? If so, what are the shapes supposed to be?  P.S. I understand delta is given through an initialization via runner.py so apparently this has nothing to do with my forward code. ',\n",
              " \"Check your code if you modified self.gamma or delta somewhere. If so, you shouldn't do that\",\n",
              " 'hw1p1']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_lst = []\n",
        "with open('/content/drive/MyDrive/11785_project/data/naive/gpt/20s_test.json', mode='r', encoding='utf-8') as f:\n",
        "    dicts = json.load(f)\n",
        "    for i in dicts:\n",
        "        check_lst.append(i)"
      ],
      "metadata": {
        "id": "HTl4VFhijzJr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_response = []\n",
        "with open('/content/drive/MyDrive/11785_project/data/naive/gpt/gpt_response.json', mode='r', encoding='utf-8') as f:\n",
        "    dicts = json.load(f)\n",
        "    for i in dicts:\n",
        "        gpt_response.append(i)"
      ],
      "metadata": {
        "id": "tfcd-4T24niG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_eval = []\n",
        "with open('/content/drive/MyDrive/11785_project/data/naive/gpt/gpt_eval.json', mode='r', encoding='utf-8') as f:\n",
        "    dicts = json.load(f)\n",
        "    for i in dicts:\n",
        "        gpt_eval.append(i)"
      ],
      "metadata": {
        "id": "vDqkXyaG4oIU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(check_lst),len(gpt_response),len(gpt_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pll0K02YkSoi",
        "outputId": "26148764-8e99-4478-8f11-63615aef096d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(464, 2468, 2468)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('data', check_lst[0])\n",
        "print('gr', gpt_response[0])\n",
        "print('ge', gpt_eval[0])"
      ],
      "metadata": {
        "id": "pvPHtlPmkSrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c745b1b7-8fde-42d4-c69d-03f167d1a309"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data {'label': 'other', 'question': \"Hello, I am registered for 11785 B but I don't see this course in my autolab.\", 'answer': 'Yep, no one has been registered on autolab yet. We will do that soon!'}\n",
            "gr {'id': 'chatcmpl-76TJn1SorxiEAvYjIt53L0E1wUP8E', 'object': 'chat.completion', 'created': 1681777023, 'model': 'gpt-3.5-turbo-0301', 'usage': {'prompt_tokens': 52, 'completion_tokens': 71, 'total_tokens': 123}, 'choices': [{'message': {'role': 'assistant', 'content': \"Hello! I'm sorry to hear that you're having trouble accessing the course on Autolab. Have you tried contacting the course instructor or the Autolab support team? They may be able to assist you in resolving the issue. Additionally, make sure that you are enrolled in the correct section of the course and that you have completed any necessary prerequisites.\"}, 'finish_reason': 'stop', 'index': 0}], 'num_examples': 0, 'label': 'other', 'prompt': [{'role': 'system', 'content': 'You are a helpful and experienced teaching assistant of a deep learning course.'}, {'role': 'user', 'content': \"Question: Hello, I am registered for 11785 B but I don't see this course in my autolab..\"}]}\n",
            "ge {'label': 'other', 'num_examples': 0, 'question': \"Hello, I am registered for 11785 B but I don't see this course in my autolab.\", 'ta_answer': 'Yep, no one has been registered on autolab yet. We will do that soon!', 'gpt_answer': \"Hello! I'm sorry to hear that you're having trouble accessing the course on Autolab. Have you tried contacting the course instructor or the Autolab support team? They may be able to assist you in resolving the issue. Additionally, make sure that you are enrolled in the correct section of the course and that you have completed any necessary prerequisites.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_content_r = []\n",
        "final_content_c = []\n",
        "for i in range(len(check_lst)):\n",
        "  for j in range(len(rmnan_pair)):\n",
        "    if check_lst[i]['question'] == rmnan_pair[j][2]:\n",
        "      final_content_r.append(rmnan_pair[j])\n",
        "      final_content_c.append(check_lst[i])\n",
        "      break"
      ],
      "metadata": {
        "id": "QuTG9QlykSuh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_content_c[20],final_content_r[20]"
      ],
      "metadata": {
        "id": "vx7Y697VkSxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e09e01-991a-46ac-ee00-46055244ff0d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'label': 'hw0',\n",
              "  'question': 'Hi, I am planning to use the Lambda system for the course instead of AWS.  I have cuda, torch and numpy installed/configured. I haven\\'t installed conda as I prefer to use pip instead. Below you can find the output of \\'numba -s\\' command which I have submitted in Autolab.  Please let me know if this is sufficient or should I have to configure the AWS.  Note : I have created a AWS account with GPU access and plan on using it only if I find the Lambda system insufficient.  (xx_python_venv) xxxx@xxx:~/xxx$ numba -sSystem info:--------------------------------------------------------------------------------__Time Stamp__2020-01-15 22:36:28.987988 __Hardware Information__Machine : x86_64CPU Name : znver1CPU count : 32CFS restrictions : NoneCPU Features : 64bit adx aes avx avx2 bmi bmi2 clflushopt clzero cmov cx16 f16c fma fsgsbaselzcnt mmx movbe mwaitx pclmul popcnt prfchw rdrnd rdseed sahf sha sse sse2 sse3sse4.1 sse4.2 sse4a ssse3 xsave xsavec xsaveopt xsaves __OS Information__Platform : Linux-5.0.0-37-generic-x86_64-with-Ubuntu-18.04-bionicRelease : 5.0.0-37-genericSystem Name : LinuxVersion : #40~18.04.1-Ubuntu SMP Thu Nov 14 12:06:39 UTC 2019OS specific info : Ubuntu18.04bionicglibc info : glibc 2.25 __Python Information__Python Compiler : GCC 8.3.0Python Implementation : CPythonPython Version : 3.6.8Python Locale : en_US UTF-8 __LLVM information__LLVM version : 8.0.0 __CUDA Information__Found 1 CUDA devicesid 0 b\\'TITAN RTX\\' [SUPPORTED] compute capability: 7.5 pci device id: 0 pci bus id: 66Summary: 1/1 devices are supportedCUDA driver version : 10010CUDA libraries:Finding cublas from &lt;unavailable&gt; ERROR: can\\'t locate libFinding cusparse from &lt;unavailable&gt; ERROR: can\\'t locate libFinding cufft from &lt;unavailable&gt; ERROR: can\\'t locate libFinding curand from &lt;unavailable&gt; ERROR: can\\'t locate libFinding nvvm from &lt;unavailable&gt; ERROR: can\\'t locate libFinding libdevice from &lt;unavailable&gt; searching for compute_20... ERROR: can\\'t open libdevice for compute_20 searching for compute_30... ERROR: can\\'t open libdevice for compute_30 searching for compute_35... ERROR: can\\'t open libdevice for compute_35 searching for compute_50... ERROR: can\\'t open libdevice for compute_50 __ROC Information__ROC available : FalseError initialising ROC due to : No ROC toolchains found.No HSA Agents found, encountered exception when searching:Error at driver init: NUMBA_HSA_DRIVER /opt/rocm/lib/libhsa-runtime64.so is not a valid file path. Note it must be a filepath of the .so/.dll/.dylib or the driver: __SVML Information__SVML state, config.USING_SVML : FalseSVML library found and loaded : Falsellvmlite using SVML patched LLVM : TrueSVML operational : False __Threading Layer Information__TBB Threading layer available : TrueOpenMP Threading layer available : False+--&gt; Disabled due to : Unknown import problem.Workqueue Threading layer available : True __Numba Environment Variable Information__None set. __Conda Information__Conda not present/not working.Error was [Errno 2] No such file or directory: \\'conda\\': \\'conda\\' --------------------------------------------------------------------------------If requested, please copy and paste the information betweenthe dashed (----) lines, or from a given specific section asappropriate. =============================================================IMPORTANT: Please ensure that you are happy with sharing thecontents of the information present, any information that youwish to keep private you should remove before sharing.============================================================= (xx_python_venv) xxxx@xxx:~/xxx$ python3Python 3.6.8 (default, Oct 7 2019, 12:59:55) [GCC 8.3.0] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import torch&gt;&gt;&gt; import numpy&gt;&gt;&gt; ',\n",
              "  'answer': \"I'd recommend copying and pasting the error into Google and seeing if anyone online has faced that error as well. \"},\n",
              " ['HW0p2 : Using Lambda system instead on AWS',\n",
              "  'HW0p2 : Using Lambda system instead on AWS',\n",
              "  'Hi, I am planning to use the Lambda system for the course instead of AWS.  I have cuda, torch and numpy installed/configured. I haven\\'t installed conda as I prefer to use pip instead. Below you can find the output of \\'numba -s\\' command which I have submitted in Autolab.  Please let me know if this is sufficient or should I have to configure the AWS.  Note : I have created a AWS account with GPU access and plan on using it only if I find the Lambda system insufficient.  (xx_python_venv) xxxx@xxx:~/xxx$ numba -sSystem info:--------------------------------------------------------------------------------__Time Stamp__2020-01-15 22:36:28.987988 __Hardware Information__Machine : x86_64CPU Name : znver1CPU count : 32CFS restrictions : NoneCPU Features : 64bit adx aes avx avx2 bmi bmi2 clflushopt clzero cmov cx16 f16c fma fsgsbaselzcnt mmx movbe mwaitx pclmul popcnt prfchw rdrnd rdseed sahf sha sse sse2 sse3sse4.1 sse4.2 sse4a ssse3 xsave xsavec xsaveopt xsaves __OS Information__Platform : Linux-5.0.0-37-generic-x86_64-with-Ubuntu-18.04-bionicRelease : 5.0.0-37-genericSystem Name : LinuxVersion : #40~18.04.1-Ubuntu SMP Thu Nov 14 12:06:39 UTC 2019OS specific info : Ubuntu18.04bionicglibc info : glibc 2.25 __Python Information__Python Compiler : GCC 8.3.0Python Implementation : CPythonPython Version : 3.6.8Python Locale : en_US UTF-8 __LLVM information__LLVM version : 8.0.0 __CUDA Information__Found 1 CUDA devicesid 0 b\\'TITAN RTX\\' [SUPPORTED] compute capability: 7.5 pci device id: 0 pci bus id: 66Summary: 1/1 devices are supportedCUDA driver version : 10010CUDA libraries:Finding cublas from &lt;unavailable&gt; ERROR: can\\'t locate libFinding cusparse from &lt;unavailable&gt; ERROR: can\\'t locate libFinding cufft from &lt;unavailable&gt; ERROR: can\\'t locate libFinding curand from &lt;unavailable&gt; ERROR: can\\'t locate libFinding nvvm from &lt;unavailable&gt; ERROR: can\\'t locate libFinding libdevice from &lt;unavailable&gt; searching for compute_20... ERROR: can\\'t open libdevice for compute_20 searching for compute_30... ERROR: can\\'t open libdevice for compute_30 searching for compute_35... ERROR: can\\'t open libdevice for compute_35 searching for compute_50... ERROR: can\\'t open libdevice for compute_50 __ROC Information__ROC available : FalseError initialising ROC due to : No ROC toolchains found.No HSA Agents found, encountered exception when searching:Error at driver init: NUMBA_HSA_DRIVER /opt/rocm/lib/libhsa-runtime64.so is not a valid file path. Note it must be a filepath of the .so/.dll/.dylib or the driver: __SVML Information__SVML state, config.USING_SVML : FalseSVML library found and loaded : Falsellvmlite using SVML patched LLVM : TrueSVML operational : False __Threading Layer Information__TBB Threading layer available : TrueOpenMP Threading layer available : False+--&gt; Disabled due to : Unknown import problem.Workqueue Threading layer available : True __Numba Environment Variable Information__None set. __Conda Information__Conda not present/not working.Error was [Errno 2] No such file or directory: \\'conda\\': \\'conda\\' --------------------------------------------------------------------------------If requested, please copy and paste the information betweenthe dashed (----) lines, or from a given specific section asappropriate. =============================================================IMPORTANT: Please ensure that you are happy with sharing thecontents of the information present, any information that youwish to keep private you should remove before sharing.============================================================= (xx_python_venv) xxxx@xxx:~/xxx$ python3Python 3.6.8 (default, Oct 7 2019, 12:59:55) [GCC 8.3.0] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import torch&gt;&gt;&gt; import numpy&gt;&gt;&gt; ',\n",
              "  'I am not sure if you can run on GPU using Lambda.  What do you think is the benefit of using Lambda over Dedicated/Spot servers?',\n",
              "  'hw0'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(final_content_r)):\n",
        "  if final_content_c[i]['answer'] != final_content_r[i][3]:\n",
        "    final_content_c[i]['answer'] = final_content_r[i][3]"
      ],
      "metadata": {
        "id": "_ZjmVehYkS0f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_content_c[20]['answer']"
      ],
      "metadata": {
        "id": "BCcKplqDkS3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54d9c8a7-8805-4973-ed9e-cda628009d44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am not sure if you can run on GPU using Lambda.  What do you think is the benefit of using Lambda over Dedicated/Spot servers?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_content_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5GPC91qeZj4",
        "outputId": "4f06dbcd-c802-49e0-c6ab-ad3548244107"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "for i in range(len(check_lst)):\n",
        "  true_labels.append(check_lst[i]['label'])"
      ],
      "metadata": {
        "id": "EEiRuMpD2vNY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_check = {}\n",
        "for key in true_labels:\n",
        "    dict_check[key] = dict_check.get(key, 0) + 1\n",
        "\n",
        "dict_check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wscalWN22vQM",
        "outputId": "01300206-14e2-4c9e-e90b-ac701a34e676"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'other': 33,\n",
              " 'hw0': 32,\n",
              " 'logistics': 27,\n",
              " 'quizzes': 47,\n",
              " 'logistics; quizzes': 4,\n",
              " 'hw0; quizzes': 2,\n",
              " 'quizzes; logistics': 2,\n",
              " 'lectures': 27,\n",
              " 'hw1p1': 34,\n",
              " 'lectures; other': 1,\n",
              " 'hw1p2': 50,\n",
              " 'hw1p2; logistics': 1,\n",
              " 'logistics; hw1p2': 2,\n",
              " 'logistics; project': 1,\n",
              " 'hw1p1; hw1p2': 1,\n",
              " 'project': 21,\n",
              " 'hw2p1': 17,\n",
              " 'hw2p2': 52,\n",
              " 'other; logistics': 1,\n",
              " 'hw3p1': 24,\n",
              " 'project; other; logistics': 1,\n",
              " 'hw3p2': 18,\n",
              " 'hw1p1; hw3p1': 1,\n",
              " 'lectures; logistics': 1,\n",
              " 'hw4p2': 38,\n",
              " 'hw4p1': 17,\n",
              " 'logistics; quizzes; hw3p2': 1,\n",
              " 'hw3p1; hw4p2': 1,\n",
              " 'hw3p1; hw3p2': 2,\n",
              " 'other; project': 1,\n",
              " 'project; logistics': 1,\n",
              " 'logistics; hw3p2': 1,\n",
              " 'hw4p2; hw3p2': 1,\n",
              " 'exam; logistics': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = []  \n",
        "list2 = []\n",
        "for k,v in dict_check.items():\n",
        "    if v > 10:\n",
        "        list1.append(k)\n",
        "        list2.append(v)\n",
        "update = dict(zip(list1,list2))\n",
        "print(len(update))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVc_LLvx2vS5",
        "outputId": "4e9952e3-7b05-4644-c404-f0d014654b35"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_name = []\n",
        "\n",
        "for k,v in update.items():\n",
        "  list_name.append(k)"
      ],
      "metadata": {
        "id": "SYY_Itio2vVw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = ['question','answer']"
      ],
      "metadata": {
        "id": "mRiBCG6U2vYo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "for i in range(len(list_name)):\n",
        "  idx = []\n",
        "  for j in range(len(check_lst)):\n",
        "        if check_lst[j]['label'] == list_name[i]:\n",
        "          idx.append(j)\n",
        "        n = len(idx)\n",
        "        seq = list(range(n))\n",
        "        train_idx = random.sample(seq,int(0.8*n))\n",
        "        test_idx = []\n",
        "        for id in seq:\n",
        "          if id not in train_idx:\n",
        "            test_idx.append(id)\n",
        "\n",
        "  filename_train = '/content/drive/MyDrive/11785_project/data/ret/20s_train/' + list_name[i] + '_ret_train.tsv'\n",
        "  filename_test = '/content/drive/MyDrive/11785_project/data/ret/20s_test/' + list_name[i] + '_ret_test.tsv'\n",
        "\n",
        "  with open(filename_train, 'w') as tsvfile1:\n",
        "      writer1 = csv.writer(tsvfile1, delimiter='\\t', lineterminator='\\n')\n",
        "      writer1.writerow(row)\n",
        "      for k in range(len(train_idx)):\n",
        "        temp_row = [check_lst[idx[train_idx[k]]]['question'], check_lst[idx[train_idx[k]]]['answer']]\n",
        "        writer1.writerow(temp_row)\n",
        "\n",
        "  with open(filename_test, 'w') as tsvfile2:\n",
        "      writer2 = csv.writer(tsvfile2, delimiter='\\t', lineterminator='\\n')\n",
        "      writer2.writerow(row)\n",
        "      for l in range(len(test_idx)):\n",
        "        temp_row = [check_lst[idx[test_idx[l]]]['question'], check_lst[idx[test_idx[l]]]['answer']]\n",
        "        writer2.writerow(temp_row)"
      ],
      "metadata": {
        "id": "x3czraNz2vbf"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}